{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "from torch.utils import data\n",
    "import os\n",
    "import zipfile\n",
    "import tarfile\n",
    "import hashlib\n",
    "import requests\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于位置的前馈网络\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"基于位置的前馈网络\"\"\"\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs, **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 8])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = PositionWiseFFN(4, 4, 8)\n",
    "ffn.eval()\n",
    "ffn(torch.ones(2,3,4)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 残差连接和层规范化\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Norm:\n",
      "\t tensor([[-1.0000,  1.0000],\n",
      "        [-1.0000,  1.0000],\n",
      "        [-1.0000,  1.0000]], grad_fn=<NativeLayerNormBackward0>) \n",
      "Batch Norm:\n",
      "\t tensor([[-1.2247e+00, -1.2247e+00],\n",
      "        [ 0.0000e+00,  1.1921e-07],\n",
      "        [ 1.2247e+00,  1.2247e+00]], grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = nn.LayerNorm(2)\n",
    "bn = nn.BatchNorm1d(2)\n",
    "X = torch.tensor([[1,2],[2,3], [3,4]], dtype=torch.float32)\n",
    "print('Layer Norm:\\n\\t', ln(X), '\\nBatch Norm:\\n\\t', bn(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'knowhow --- torch.nn中LN和BN的参数\\nnn.LayerNorm是PyTorch中用于实现层归一化(Layer Normalization)的类, 类声明如下: \\n    class torch.nn.LayerNorm(normalized_shape, eps=1e-05, elementwise_affine=True)\\n    -- normalized_shape: 一个整数或整数元组,指定输入张量的形状。例如,如果输入张量的形状是 (batch_size, num_features),\\n                        则normalized_shape应为 num_features。\\n    -- eps: 一个小的浮点数,用于数值稳定性\\n    -- elementwise_affine:一个布尔值, 指定是否应用可学习的仿射变换。如果为True,则会为每个归一化维度添加可学习的仿射变换\\n\\nnn.BatchNorm1D是PyTorch中用于实现一维批归一化(Batch Normalization)的类, 类声明如下: \\n    class torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n    -- num_features:一个整数,指定输入张量的特征维度\\n    -- eps:一个小的浮点数,用于数值稳定性\\n    -- momentum:一个浮点数,用于计算运行平均值和方差的动量\\n    -- affine:一个布尔值,指定是否应用可学习的仿射变换。如果为True,则会为每个特征维度添加可学习的仿射变换\\n    -- track_running_stats:一个布尔值,指定是否应该跟踪运行时的统计信息(平均值和方差)。如果为True,则在训练过程\\n                            中会计算并跟踪这些统计信息,以便在推理时使用\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"knowhow --- torch.nn中LN和BN的参数\n",
    "nn.LayerNorm是PyTorch中用于实现层归一化(Layer Normalization)的类, 类声明如下: \n",
    "    class torch.nn.LayerNorm(normalized_shape, eps=1e-05, elementwise_affine=True)\n",
    "    -- normalized_shape: 一个整数或整数元组,指定输入张量的形状。例如,如果输入张量的形状是 (batch_size, num_features),\n",
    "                        则normalized_shape应为 num_features。\n",
    "    -- eps: 一个小的浮点数,用于数值稳定性\n",
    "    -- elementwise_affine:一个布尔值, 指定是否应用可学习的仿射变换。如果为True,则会为每个归一化维度添加可学习的仿射变换\n",
    "\n",
    "nn.BatchNorm1D是PyTorch中用于实现一维批归一化(Batch Normalization)的类, 类声明如下: \n",
    "    class torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    -- num_features:一个整数,指定输入张量的特征维度\n",
    "    -- eps:一个小的浮点数,用于数值稳定性\n",
    "    -- momentum:一个浮点数,用于计算运行平均值和方差的动量\n",
    "    -- affine:一个布尔值,指定是否应用可学习的仿射变换。如果为True,则会为每个特征维度添加可学习的仿射变换\n",
    "    -- track_running_stats:一个布尔值,指定是否应该跟踪运行时的统计信息(平均值和方差)。如果为True,则在训练过程\n",
    "                            中会计算并跟踪这些统计信息,以便在推理时使用\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    \"\"\"残差连接后进行层规范化\"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "    \n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y)+X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_norm = AddNorm([3,4], 0.5)\n",
    "add_norm.eval()\n",
    "add_norm(torch.ones((2,3,4)), torch.ones((2,3,4))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编码器\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"在序列中遮蔽不相关的项\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32, device=X.device)[None,:] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作\"\"\"\n",
    "    ## X: 3D张量 valid_lens: 1D或2D张量\n",
    "    if valid_lens is None:\n",
    "        return F.softmax(X, dim=-1)\n",
    "    shape = X.shape\n",
    "    if valid_lens.dim() == 1:\n",
    "        valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "    else:\n",
    "        valid_lens = valid_lens.reshape(-1)\n",
    "    X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)\n",
    "    return F.softmax(X.reshape(shape), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"缩放点积注意力\"\"\"\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        ## queries的形状: (batch_size, 查询个数, d)\n",
    "        ## keys的形状: (batch_size, 键值对个数, d)\n",
    "        ## values的形状: (batch_size, 键值对个数, 值的维度)\n",
    "        ## valid_lens的形状: (batch_size,)或(batch_size, 查询个数)\n",
    "        d = queries.shape[-1]\n",
    "        scores = torch.bmm(queries, keys.transpose(1,2))/math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 输入X形状: (batch_size, 查询或键值对个数, num_hiddens)\n",
    "def transpose_qkv(X, num_heads):\n",
    "    \"\"\"为了多注意力头的并行计算而变换形状\"\"\"\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)    ## (batch_size, 查询或键值对个数, num_heads, num_hiddens/num_heads)\n",
    "    X = X.permute(0, 2, 1, 3) ## (batch_size, num_heads, 查询或键值对个数, num_hiddens/num_heads)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3]) ## (batch_size*num_heads, 查询或键值对个数, num_hiddens/num_heads)\n",
    "\n",
    "def transpose_output(X, num_heads):\n",
    "    \"\"\"逆转transpose_qkv函数的操作\"\"\"\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "    \n",
    "    ## queries, keys, values的形状: (batch_size, 查询或键值对数, num_hiddens)\n",
    "    ## valid_lens的形状: (batch_size,)或(batch_size, 查询的个数)\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            valid_lens = torch.repeat_interleave(\n",
    "                valid_lens, repeats=self.num_heads, dim=0\n",
    "            )\n",
    "        output = self.attention(queries, keys, values, valid_lens)  ## (batch_size*num_heads, 查询个数, num_hiddens/num_heads)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, \n",
    "            num_heads, dropout, use_bias\n",
    "        )\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(\n",
    "            ffn_num_input, ffn_num_hiddens, num_hiddens\n",
    "        )\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((2, 100, 24))\n",
    "valid_lens = torch.tensor([3,2])\n",
    "encoder_blk = EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)\n",
    "encoder_blk.eval()\n",
    "encoder_blk(X, valid_lens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本编码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "    def forward(self, X, *args):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"位置编码\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(-1,1)/\\\n",
    "        torch.pow(10000, torch.arange(0, num_hiddens, 2, dtype=torch.float32)/num_hiddens)\n",
    "        self.P[:,:,0::2] = torch.sin(X)\n",
    "        self.P[:,:,1::2] = torch.cos(X)\n",
    "    def forward(self, X):\n",
    "        X += self.P[:,:X.shape[1],:].to(X.device)\n",
    "        return self.dropout(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(Encoder):\n",
    "    \"\"\"Transformer编码器\"\"\"\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, \n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\n",
    "                'block'+str(i),\n",
    "                EncoderBlock(\n",
    "                    key_size, query_size, value_size, num_hiddens,\n",
    "                    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, \n",
    "                    dropout, use_bias\n",
    "                )\n",
    "            ) \n",
    "    \n",
    "    def forward(self, X, valid_lens, *args):\n",
    "        ## 因为位置编码在-1和1之间,因此嵌入值乘以嵌入维度的平方根进行缩放然后再与位置编码相加\n",
    "        X = self.pos_encoding(self.embedding(X)*math.sqrt(self.num_hiddens))\n",
    "        self.attention_weights = [None]*len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens)\n",
    "            self.attention_weights[i] = blk.attention.attention.attention_weights\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = TransformerEncoder(\n",
    "    200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5\n",
    ")\n",
    "encoder.eval()\n",
    "encoder(torch.ones((2,100), dtype=torch.long), valid_lens).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解码器\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"解码器中第i个块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention1 = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens,\n",
    "            num_heads, dropout\n",
    "        )\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens,\n",
    "            num_heads, dropout\n",
    "        )\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "    \n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        ## 训练阶段,输出序列的所有词元都在同一时间处理, \n",
    "        ## 因此state[2][self.i]初始化为None\n",
    "        ## 预测阶段,输出序列是通过一个一个词元解码的,因此\n",
    "        ## state[2][self.i]包含着直到当前时间步第i个块解码的\n",
    "        ## 输出表示\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = torch.cat((state[2][self.i], X), axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "        if self.training:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            dec_valid_lens = torch.arange(\n",
    "                1, num_steps+1, device=X.device \n",
    "            ).repeat(batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "        ## 自注意力\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        ## 编码器-解码器注意力\n",
    "        ## enc_outputs的开头: (batch_size, num_steps, num_hiddens)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_blk = DecoderBlock(\n",
    "    24,24,24,24,[100,24],24,48,8,0.5,0\n",
    ")\n",
    "X = torch.ones((2,100,24))\n",
    "state = [encoder_blk(X, valid_lens), valid_lens, [None]]\n",
    "decoder_blk(X, state)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        raise NotImplementedError\n",
    "    def forward(self, X, state):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder(Decoder):\n",
    "    \"\"\"带有注意力机制解码器的基本接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "    \n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(AttentionDecoder):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\n",
    "                'block' + str(i),\n",
    "                DecoderBlock(\n",
    "                    key_size, query_size, value_size, num_hiddens,\n",
    "                    norm_shape, ffn_num_input, ffn_num_hiddens, \n",
    "                    num_heads, dropout, i\n",
    "                )\n",
    "            )\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "    \n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        return [enc_outputs, enc_valid_lens, [None]*self.num_layers]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        X = self.pos_encoding(self.embedding(X)*math.sqrt(self.num_hiddens))\n",
    "        self._attention_weights = [[None]*len(self.blks) for _ in range(2)]\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "            ## 解码器自注意力权重\n",
    "            self._attention_weights[0][i] \\\n",
    "                = blk.attention1.attention.attention_weights\n",
    "            ## 编码器-解码器自注意力权重\n",
    "            self._attention_weights[1][i] \\\n",
    "                = blk.attention2.attention.attention_weights\n",
    "        return self.dense(X), state\n",
    "        \n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器的基类\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HUB = dict()\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(name, cache_dir=None):\n",
    "    \"\"\"下载一个DATA_HUB中的文件,返回本地文件名\"\"\"\n",
    "    assert name in DATA_HUB, f\"{name} not in {DATA_HUB}\"\n",
    "    cache_dir = os.path.join('..', 'data') if cache_dir is None else cache_dir\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    if os.path.exists(fname):\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "            if sha1.hexdigest() == sha1_hash:\n",
    "                return fname\n",
    "    print(f\"Downloading {name} from {url} to {fname}...\")\n",
    "    raw_data = requests.get(url, stream=True, verify=True)\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(raw_data.content)\n",
    "    return fname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset_and_extract(name, folder=None):\n",
    "    \"\"\"下载并解压zip/tar文件\"\"\"\n",
    "    fname = download_dataset(name)\n",
    "    base_dir = os.path.dirname(fname)\n",
    "    data_dir, ext = os.path.splitext(fname)\n",
    "    match ext:\n",
    "        case '.zip':\n",
    "            fp = zipfile.ZipFile(fname, 'r')\n",
    "        case '.tar', '.gz':\n",
    "            fp = tarfile.open(fname, 'r')\n",
    "        case _:\n",
    "            assert False, f'不支持的文件类型：{ext}'\n",
    "    fp.extractall(path=base_dir)\n",
    "    fp.close()\n",
    "    return os.path.join(base_dir, folder) if folder else data_dir\n",
    "\n",
    "def download_all_datasets():\n",
    "    \"\"\"下载DATA_HUB中的所有数据集\"\"\"\n",
    "    for name in DATA_HUB:\n",
    "        download_dataset(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HUB['fra-eng'] = (DATA_URL + 'fra-eng.zip',\n",
    "                       '94646ad1522d915e7b0f9296181140edcf86a4f5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_nmt():\n",
    "    \"\"\"载入'英语-法语'数据集\"\"\"\n",
    "    data_dir = download_dataset_and_extract('fra-eng')\n",
    "    with open(os.path.join(data_dir, 'fra.txt'), 'r', encoding='utf-8') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_nmt(text):\n",
    "    \"\"\"预处理'英语-法语'数据集\"\"\"\n",
    "    def no_space(char, prev_char):\n",
    "        return char in set(',.!?') and prev_char != ' '\n",
    "    ## 使用空格替换不间断空格，使用小写字母替换大写字母\n",
    "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
    "    ## 在单词和标点符号之间插入空格\n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i-1]) else char for i, char in enumerate(text)]\n",
    "    return ''.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_nmt(text, num_examples=None):\n",
    "    \"\"\"词元化'英语-法语'数据数据集\"\"\"\n",
    "    source, target = [], []\n",
    "    for i, line in enumerate(text.split('\\n')):\n",
    "        if num_examples and i > num_examples:\n",
    "            break\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            source.append(parts[0].split(' '))\n",
    "            target.append(parts[1].split(' '))\n",
    "    return source, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    \"\"\"文本词表\"\"\"\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        tokens = [] if tokens is None else tokens\n",
    "        reserved_tokens = [] if reserved_tokens is None else reserved_tokens\n",
    "        ## 按出现频率排序\n",
    "        counter = Vocab.count_corpus(tokens)\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "        self.idx2token = ['<unk>'] + reserved_tokens\n",
    "        self.token2idx = {token: idx for idx, token in enumerate(self.idx2token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token2idx:\n",
    "                self.idx2token.append(token)\n",
    "                self.token2idx[token] = len(self.idx2token)-1\n",
    "    def __len__(self):\n",
    "        return len(self.idx2token)\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token2idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx2token[indices]\n",
    "        return [self.idx2token[index] for index in indices]\n",
    "    @property\n",
    "    def unk(self):\n",
    "        return 0\n",
    "    @property\n",
    "    def token_freqs(self):\n",
    "        return self._token_freqs \n",
    "    @staticmethod\n",
    "    def count_corpus(tokens):\n",
    "        \"\"\"统计词元频率\"\"\"\n",
    "        if isinstance(tokens[0], list):\n",
    "            tokens = [token for line in tokens for token in line]\n",
    "        return collections.Counter(tokens)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"截断或填充文本序列\"\"\"\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]\n",
    "    return line + [padding_token]*(num_steps-len(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_array_nmt(lines, vocab, num_steps):\n",
    "    \"\"\"将机器翻译的文本序列转换成小批量\"\"\"\n",
    "    lines = [vocab[l] for l in lines]\n",
    "    lines = [l + [vocab['<eos>']] for l in lines]\n",
    "    array = torch.tensor(\n",
    "        [truncate_pad(l, num_steps, vocab['<pad>']) for l in lines]\n",
    "    )\n",
    "    valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
    "    return array, valid_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"构造一个PyTorch数据迭代器\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size=batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_nmt(batch_size, num_steps, num_examples=600):\n",
    "    \"\"\"返回翻译数据集的迭代器和词表\"\"\"\n",
    "    text = preprocess_nmt(read_data_nmt())\n",
    "    source, target = tokenize_nmt(text, num_examples)\n",
    "    src_vocab = Vocab(source, min_freq=2, reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    tgt_vocab = Vocab(target, min_freq=2, reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
    "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
    "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "    data_iter = load_array(data_arrays, batch_size=batch_size)\n",
    "    return data_iter, src_vocab, tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    \"\"\"记录多次运行时间\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "    def start(self):\n",
    "        \"\"\"启动计时器\"\"\"\n",
    "        self.tik = time.time()\n",
    "    def stop(self):\n",
    "        \"\"\"停止计时器并将时间记录在列表中\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "    def avg(self):\n",
    "        \"\"\"返回平均时间\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "    def sum(self):\n",
    "        \"\"\"返回时间总和\"\"\"\n",
    "        return sum(self.times)\n",
    "    def cumsum(self):\n",
    "        \"\"\"返回累计时间\"\"\"\n",
    "        return np.cumsum(self.times).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "    def __init__(self, n):\n",
    "        self.data = [.0] * n\n",
    "    def add(self, *args):\n",
    "        self.data = [a+float(b) for a, b in zip(self.data, args)]\n",
    "    def reset(self):\n",
    "        self.data = [.0] * len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animator:\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, xlim=None, ylim=None,\n",
    "                xscale='linear', yscale='linear', legend=None,\n",
    "                fmts=('-', 'm--', 'g-.', 'r:')):\n",
    "        ## 增量地绘制多条线\n",
    "        legend = [] if legend is None else legend\n",
    "        self.fig, self.axes = plt.gcf(), plt.gca()\n",
    "        self.config_axes = lambda: self.set_axes(xlabel, ylabel, xlim, ylim, xscale, yscale, legend) ## 使用lambda表达式捕获变量\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def set_axes(self, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "        self.axes.set_xlabel(xlabel)\n",
    "        self.axes.set_ylabel(ylabel)\n",
    "        self.axes.set_xlim(xlim)\n",
    "        self.axes.set_ylim(ylim)\n",
    "        self.axes.set_xscale(xscale)\n",
    "        self.axes.set_yscale(yscale)\n",
    "        self.axes.legend(legend)\n",
    "        self.axes.grid()\n",
    "\n",
    "    def add(self, x, y):\n",
    "        \"\"\"向图表中添加多个数据点\"\"\"\n",
    "        y = [y] if not hasattr(y, \"__len__\") else y\n",
    "        x = [x] * len(y) if not hasattr(x, \"__len__\") else x\n",
    "        self.X = [[] for _ in range(len(y))] if self.X is None else self.X\n",
    "        self.Y = [[] for _ in range(len(y))] if self.Y is None else self.Y\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes.cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes.plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(net, theta):\n",
    "    \"\"\"裁剪梯度\"\"\"\n",
    "    params = [p for p in net.parameters() if p.requires_grad]\n",
    "    norm = torch.sqrt(sum(torch.sum(p.grad**2) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad *= theta/norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    \"\"\"带遮蔽的softmax交叉熵损失函数\"\"\"\n",
    "    ## pred      --> (batch_size, num_steps, vocab_size)\n",
    "    ## label     --> (batch_size, num_steps)\n",
    "    ## valid_len --> (batch_size, )\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction = 'none'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
    "            pred.permute(0, 2, 1), label\n",
    "        )\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    \"\"\"训练序列到序列模型\"\"\"\n",
    "    def xavier_init_weights(m):\n",
    "        match type(m):\n",
    "            case nn.Linear:\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "            case nn.GRU:\n",
    "                for param in m._flat_weights_names:\n",
    "                    if 'weight' in param:\n",
    "                        nn.init.xavier_normal_(m._parameters[param])\n",
    "            case _:\n",
    "                pass\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    animator = Animator(xlabel='epoch', ylabel='loss', xlim=[10, num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        timer = Timer()\n",
    "        metric = Accumulator(2)  ## 训练损失总和,词元数量\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']]*Y.shape[0], device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()\n",
    "            grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            animator.add(epoch+1, (metric[0]/metric[1],))\n",
    "    print(f'loss {metric[0]/metric[1]:.3f}, {metric[1]/timer.stop():.1f} '\n",
    "          f'tokens/sec on {str(device)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.031, 2584.2 tokens/sec on cpu\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_hiddens, num_layers, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 10\n",
    "lr, num_epochs, device = 0.005, 200, torch.device('cpu')\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [32]\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size, num_steps)\n",
    "encoder = TransformerEncoder(\n",
    "    len(src_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout\n",
    ")\n",
    "decoder = TransformerDecoder(\n",
    "    len(tgt_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout\n",
    ")\n",
    "net = EncoderDecoder(encoder, decoder)\n",
    "train(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net, src_sentence, src_vocab, tgt_vocab, num_steps, device, save_attention_weights=False):\n",
    "    \"\"\"序列到序列模型的预测\"\"\"\n",
    "    ## 在预测时把net置为评估模式\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')]+[src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    ## 添加批量维度\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), \n",
    "        dim=0\n",
    "    )\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    ## 添加批量维度\n",
    "    dec_X = torch.unsqueeze(\n",
    "        torch.tensor([tgt_vocab['<bos>']], dtype=torch.long, device=device),\n",
    "        dim = 0\n",
    "    )\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(pred_seq, label_seq, k):\n",
    "    \"\"\"计算bleu\"\"\"\n",
    "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    score = math.exp(min(0, 1-len_label/len_pred))\n",
    "    for n in range(1, k+1):\n",
    "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
    "        for i in range(len_label-n+1):\n",
    "            label_subs[' '.join(label_tokens[i:i+n])] += 1\n",
    "        for i in range(len_pred-n+1):\n",
    "            if label_subs[' '.join(pred_tokens[i:i+n])] > 0:\n",
    "                num_matches += 1\n",
    "                label_subs[' '.join(pred_tokens[i:i+n])] -= 1\n",
    "        score *= math.pow(num_matches / (len_pred-n+1), math.pow(0.5, n))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . => va !,  bleu 1.000\n",
      "i lost . => j'ai perdu .,  bleu 1.000\n",
      "he's calm . => il est calme .,  bleu 1.000\n",
      "i'm home . => je suis chez moi .,  bleu 1.000\n"
     ]
    }
   ],
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, dec_attention_weight_seq = predict(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device, True\n",
    "    )\n",
    "    print(f'{eng} => {translation}, ',\n",
    "          f'bleu {bleu(translation, fra, k=2):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 在实验中训练更深的Transformer将如何影响训练速度和翻译效果？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 在Transformer中使用加性注意力取代缩放点积注意力是不是个好办法？为什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 对于语言模型，应该使用Transformer的编码器还是解码器，或者两者都用？如何设计？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 如果输入序列很长，Transformer会面临什么挑战？为什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 如何提高Transformer的计算速度和内存使用效率？提示：可以参考论文 (Tay et al., 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 如果不使用卷积神经网络，如何设计基于Transformer模型的图像分类任务？提示：可以参考Vision Transformer (Dosovitskiy et al., 2021)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
